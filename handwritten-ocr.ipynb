{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1821108,"sourceType":"datasetVersion","datasetId":1081982}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Below are all the modules that are used in the notebook.","metadata":{}},{"cell_type":"code","source":"# Common\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom IPython.display import clear_output as cls\n\n# Data\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow.data as tfd\n\n# Data Visualization\nimport matplotlib.pyplot as plt\n\n# Model\nfrom tensorflow import keras\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:10:23.909557Z","iopub.execute_input":"2023-03-06T00:10:23.909928Z","iopub.status.idle":"2023-03-06T00:10:23.925699Z","shell.execute_reply.started":"2023-03-06T00:10:23.909897Z","shell.execute_reply":"2023-03-06T00:10:23.921272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Size\nIMG_WIDTH = 200\nIMG_HEIGHT = 50\nIMAGE_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n\n# Batch Size\nBATCH_SIZE = 16\n\n# EPOCHS\nEPOCHS = 100\n\n# Model Name\nMODEL_NAME = 'Handwritten-OCR'\n\n# Callbacks\nCALLBACKS = [\n    callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n    callbacks.ModelCheckpoint(filepath=MODEL_NAME + \".h5\", save_best_only=True)\n]\n\n# Learning Rate\nLEARNING_RATE = 1e-3\n\n# Random Seed\nnp.random.seed(2569)\ntf.random.set_seed(2569)\n\n# File Paths\ntrain_csv_path = '/kaggle/input/handwriting-recognitionocr/CSV/written_name_train.csv'\nvalid_csv_path = '/kaggle/input/handwriting-recognitionocr/CSV/written_name_validation.csv'\ntest_csv_path = '/kaggle/input/handwriting-recognitionocr/CSV/written_name_test.csv'\n\ntrain_image_dir = '/kaggle/input/handwriting-recognitionocr/train_v2/train'\nvalid_image_dir = '/kaggle/input/handwriting-recognitionocr/validation_v2/validation'\ntest_image_dir = '/kaggle/input/handwriting-recognitionocr/test_v2/test'\n\n# Data Size\nTRAIN_SIZE = BATCH_SIZE * 1000\nVALID_SIZE = BATCH_SIZE * 500\nTEST_SIZE  = BATCH_SIZE * 100\n\n# AUTOTUNE\nAUTOTUNE = tfd.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.045139Z","iopub.execute_input":"2023-03-05T22:56:55.046283Z","iopub.status.idle":"2023-03-05T22:56:55.057359Z","shell.execute_reply.started":"2023-03-05T22:56:55.046243Z","shell.execute_reply":"2023-03-05T22:56:55.05642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train CSV\ntrain_csv = pd.read_csv(train_csv_path)[:TRAIN_SIZE]\n\n# Validation CSV\nvalid_csv = pd.read_csv(valid_csv_path)[:VALID_SIZE]\n\n# Test CSV\ntest_csv = pd.read_csv(test_csv_path)[:TEST_SIZE]","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.05914Z","iopub.execute_input":"2023-03-05T22:56:55.059544Z","iopub.status.idle":"2023-03-05T22:56:55.520124Z","shell.execute_reply.started":"2023-03-05T22:56:55.059507Z","shell.execute_reply":"2023-03-05T22:56:55.519121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.523201Z","iopub.execute_input":"2023-03-05T22:56:55.523624Z","iopub.status.idle":"2023-03-05T22:56:55.541Z","shell.execute_reply.started":"2023-03-05T22:56:55.523576Z","shell.execute_reply":"2023-03-05T22:56:55.5399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all train labels\ntrain_labels = [str(word) for word in train_csv['IDENTITY'].to_numpy()]\ntrain_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.542583Z","iopub.execute_input":"2023-03-05T22:56:55.543013Z","iopub.status.idle":"2023-03-05T22:56:55.557574Z","shell.execute_reply.started":"2023-03-05T22:56:55.542977Z","shell.execute_reply":"2023-03-05T22:56:55.556637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unique characters\nunique_chars = set(char for word in train_labels for char in word)\nn_classes = len(unique_chars)\n\n# Show\nprint(f\"Total number of unique characters : {n_classes}\")\nprint(f\"Unique Characters : \\n{unique_chars}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.559196Z","iopub.execute_input":"2023-03-05T22:56:55.559996Z","iopub.status.idle":"2023-03-05T22:56:55.575013Z","shell.execute_reply.started":"2023-03-05T22:56:55.559959Z","shell.execute_reply":"2023-03-05T22:56:55.573902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LABEL_LENGTH = max(map(len, train_labels))\nprint(f\"Maximum length of a label : {MAX_LABEL_LENGTH}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.57652Z","iopub.execute_input":"2023-03-05T22:56:55.576955Z","iopub.status.idle":"2023-03-05T22:56:55.586031Z","shell.execute_reply.started":"2023-03-05T22:56:55.576917Z","shell.execute_reply":"2023-03-05T22:56:55.584904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv['FILENAME'] = [train_image_dir + f\"/{filename}\" for filename in train_csv['FILENAME']]\nvalid_csv['FILENAME'] = [valid_image_dir + f\"/{filename}\" for filename in valid_csv['FILENAME']]\ntest_csv['FILENAME']  = [test_image_dir + f\"/{filename}\" for filename in test_csv['FILENAME']]","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.587525Z","iopub.execute_input":"2023-03-05T22:56:55.588318Z","iopub.status.idle":"2023-03-05T22:56:55.609993Z","shell.execute_reply.started":"2023-03-05T22:56:55.588281Z","shell.execute_reply":"2023-03-05T22:56:55.609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.611447Z","iopub.execute_input":"2023-03-05T22:56:55.612214Z","iopub.status.idle":"2023-03-05T22:56:55.626295Z","shell.execute_reply.started":"2023-03-05T22:56:55.612176Z","shell.execute_reply":"2023-03-05T22:56:55.624767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Character to numeric value dictionary\nchar_to_num = layers.StringLookup(\n    vocabulary = list(unique_chars),\n    mask_token = None\n)\n\n# Reverse dictionary\nnum_to_char = layers.StringLookup(\n    vocabulary = char_to_num.get_vocabulary(),\n    mask_token = None, \n    invert = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:55.630995Z","iopub.execute_input":"2023-03-05T22:56:55.631283Z","iopub.status.idle":"2023-03-05T22:56:58.188029Z","shell.execute_reply.started":"2023-03-05T22:56:55.631254Z","shell.execute_reply":"2023-03-05T22:56:58.187011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_path : str):\n    '''\n    This function loads and preprocesses images. It first receives the image path, which is used to\n    decode the image as a JPEG using TensorFlow. Then, it converts the image to a tensor and applies \n    two processing functions: resizing and normalization. The processed image is then returned by \n    the function.\n    \n    Argument : \n        image_path : The path of the image file to be loaded.\n    \n    Return:\n        image : The loaded image as a tensor.\n    '''\n    \n    # Read the Image\n    image = tf.io.read_file(image_path)\n    \n    # Decode the image\n    decoded_image = tf.image.decode_jpeg(contents = image, channels = 1)\n    \n    # Convert image data type.\n    cnvt_image = tf.image.convert_image_dtype(image = decoded_image, dtype = tf.float32)\n    \n    # Resize the image\n    resized_image = tf.image.resize(images = cnvt_image, size = (IMG_HEIGHT, IMG_WIDTH))\n    \n    # Transpose\n    image = tf.transpose(resized_image, perm = [1, 0, 2])\n    \n    # Convert image to a tensor.\n    image = tf.cast(image, dtype = tf.float32)\n    \n    # Return loaded image\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:58.1912Z","iopub.execute_input":"2023-03-05T22:56:58.191561Z","iopub.status.idle":"2023-03-05T22:56:58.199452Z","shell.execute_reply.started":"2023-03-05T22:56:58.191532Z","shell.execute_reply":"2023-03-05T22:56:58.198157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_single_sample(image_path : str, label : str):\n    \n    '''\n    The function takes an image path and label as input and returns a dictionary containing the processed image tensor and the label tensor. \n    First, it loads the image using the load_image function, which decodes and resizes the image to a specific size. Then it converts the given\n    label string into a sequence of Unicode characters using the unicode_split function. Next, it uses the char_to_num layer to convert each\n    character in the label to a numerical representation. It pads the numerical representation with a special class (n_classes)\n    to ensure that all labels have the same length (MAX_LABEL_LENGTH). Finally, it returns a dictionary containing the processed image tensor\n    and the label tensor.\n    \n    Arguments : \n        image_path : The location of the image file.\n        label      : The text to present in the image.\n    \n    Returns:\n        dict : A dictionary containing the processed image and label.\n    '''\n    \n    # Get the image\n    image = load_image(image_path)\n    \n    # Convert the label into characters\n    chars = tf.strings.unicode_split(label, input_encoding='UTF-8')\n    \n    # Convert the characters into vectors\n    vecs = char_to_num(chars)\n    \n    # Pad label\n    pad_size = MAX_LABEL_LENGTH - tf.shape(vecs)[0]\n    vecs = tf.pad(vecs, paddings = [[0, pad_size]], constant_values=n_classes+1)\n    \n    return {'image':image, 'label':vecs}","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:58.20105Z","iopub.execute_input":"2023-03-05T22:56:58.201702Z","iopub.status.idle":"2023-03-05T22:56:58.212966Z","shell.execute_reply.started":"2023-03-05T22:56:58.201665Z","shell.execute_reply":"2023-03-05T22:56:58.211862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Data\ntrain_ds = tf.data.Dataset.from_tensor_slices(\n    (np.array(train_csv['FILENAME'].to_list()), np.array(train_csv['IDENTITY'].to_list()))\n).shuffle(1000).map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\n# Validation data\nvalid_ds = tf.data.Dataset.from_tensor_slices(\n    (np.array(valid_csv['FILENAME'].to_list()), np.array(valid_csv['IDENTITY'].to_list()))\n).map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\n# Testing data.\ntest_ds = tf.data.Dataset.from_tensor_slices(\n    (np.array(test_csv['FILENAME'].to_list()), np.array(test_csv['IDENTITY'].to_list()))\n).map(encode_single_sample, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:58.214537Z","iopub.execute_input":"2023-03-05T22:56:58.215043Z","iopub.status.idle":"2023-03-05T22:56:58.574594Z","shell.execute_reply.started":"2023-03-05T22:56:58.215004Z","shell.execute_reply":"2023-03-05T22:56:58.573591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training Data Size   : {tf.data.Dataset.cardinality(train_ds).numpy() * BATCH_SIZE}\")\nprint(f\"Validation Data Size : {tf.data.Dataset.cardinality(valid_ds).numpy() * BATCH_SIZE}\")\nprint(f\"Testing Data Size    : {tf.data.Dataset.cardinality(test_ds).numpy() * BATCH_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:56:58.576112Z","iopub.execute_input":"2023-03-05T22:56:58.576471Z","iopub.status.idle":"2023-03-05T22:56:58.585095Z","shell.execute_reply.started":"2023-03-05T22:56:58.576432Z","shell.execute_reply":"2023-03-05T22:56:58.583284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(data, GRID=[4,4], FIGSIZE=(25, 8), cmap='binary_r', model=None, decode_pred=None):\n    \n    # Plotting configurations\n    plt.figure(figsize=FIGSIZE)\n    n_rows, n_cols = GRID\n    \n    # Loading Data \n    data = next(iter(data))\n    images, labels = data['image'], data['label']\n    \n    # Iterate over the data \n    for index, (image, label) in enumerate(zip(images, labels)):\n        \n        # Label processing\n        text_label = num_to_char(label)\n        text_label = tf.strings.reduce_join(text_label).numpy().decode('UTF-8')\n        text_label = text_label.replace(\"[UNK]\", \" \").strip()\n        \n        # Create a sub plot\n        plt.subplot(n_rows, n_cols, index+1)\n        plt.imshow(tf.transpose(image, perm=[1,0,2]), cmap=cmap)\n        plt.axis('off')\n        \n        if model is not None and decode_pred is not None:\n            # Make prediction\n            pred = model.predict(tf.expand_dims(image, axis=0))\n            pred = decode_pred(pred)[0]\n            title = f\"True : {text_label}\\nPred : {pred}\"\n            plt.title(title)\n        else:\n            # add title\n            plt.title(text_label)\n\n    # Show the final plot\n    cls()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:11:26.27669Z","iopub.execute_input":"2023-03-06T00:11:26.277138Z","iopub.status.idle":"2023-03-06T00:11:26.300295Z","shell.execute_reply.started":"2023-03-06T00:11:26.2771Z","shell.execute_reply":"2023-03-06T00:11:26.29919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(data=train_ds, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:11:26.484605Z","iopub.execute_input":"2023-03-06T00:11:26.485727Z","iopub.status.idle":"2023-03-06T00:11:27.409657Z","shell.execute_reply.started":"2023-03-06T00:11:26.48566Z","shell.execute_reply":"2023-03-06T00:11:27.408678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CTCLayer(layers.Layer):\n    \n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        \n        self.loss_fn = keras.backend.ctc_batch_cost\n    \n    def call(self, y_true, y_pred):\n        \n        batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n        \n        input_len = tf.cast(tf.shape(y_pred)[1], dtype='int64') * tf.ones(shape=(batch_len, 1), dtype='int64')\n        label_len = tf.cast(tf.shape(y_true)[1], dtype='int64') * tf.ones(shape=(batch_len, 1), dtype='int64')\n        \n        loss = self.loss_fn(y_true, y_pred, input_len, label_len)\n        \n        self.add_loss(loss)\n        \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:57:00.109364Z","iopub.execute_input":"2023-03-05T22:57:00.109737Z","iopub.status.idle":"2023-03-05T22:57:00.120907Z","shell.execute_reply.started":"2023-03-05T22:57:00.109697Z","shell.execute_reply":"2023-03-05T22:57:00.11978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **OCR Model**","metadata":{}},{"cell_type":"code","source":"# Input Layer\ninput_images = layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1), name=\"image\")\n\n# Labels : These are added for the training purpose.\ntarget_labels = layers.Input(shape=(None, ), name=\"label\")\n\n# CNN Network\nx = layers.Conv2D(\n    filters=32, \n    kernel_size=3,\n    strides=1,\n    padding='same',\n    activation='relu',\n    kernel_initializer='he_normal'\n)(input_images)\n\nx = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n\nx = layers.Conv2D(\n    filters=64, \n    kernel_size=3,\n    strides=1,\n    padding='same',\n    activation='relu',\n    kernel_initializer='he_normal'\n)(x)\n\nx = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n\n# Encoding Space\nencoding = layers.Reshape(target_shape=((IMG_WIDTH//4), (IMG_HEIGHT//4)*64))(x)\nencoding = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(encoding)\nencoding = layers.Dropout(0.2)(encoding)\n\n# RNN Network\nx = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(encoding)\nx = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n\n# Output Layer\noutput = layers.Dense(len(char_to_num.get_vocabulary())+1, activation='softmax')(x)\n\n# CTC Layer\nctc_layer = CTCLayer()(target_labels, output)\n\n# Model \nocr_model = keras.Model(\n    inputs=[input_images, target_labels],\n    outputs=[ctc_layer]\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:57:00.123077Z","iopub.execute_input":"2023-03-05T22:57:00.123952Z","iopub.status.idle":"2023-03-05T22:57:01.440177Z","shell.execute_reply.started":"2023-03-05T22:57:00.123915Z","shell.execute_reply":"2023-03-05T22:57:01.439147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Summary\nocr_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:57:01.441632Z","iopub.execute_input":"2023-03-05T22:57:01.441981Z","iopub.status.idle":"2023-03-05T22:57:01.481545Z","shell.execute_reply.started":"2023-03-05T22:57:01.441943Z","shell.execute_reply":"2023-03-05T22:57:01.480769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(ocr_model)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:57:01.482555Z","iopub.execute_input":"2023-03-05T22:57:01.483212Z","iopub.status.idle":"2023-03-05T22:57:01.850783Z","shell.execute_reply.started":"2023-03-05T22:57:01.483175Z","shell.execute_reply":"2023-03-05T22:57:01.84958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile\nocr_model.compile(optimizer='adam')\n\n# Train\nhistory = ocr_model.fit(\n    train_ds, \n    validation_data=valid_ds, \n    epochs=EPOCHS,\n    callbacks=CALLBACKS\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T22:57:01.855973Z","iopub.execute_input":"2023-03-05T22:57:01.85665Z","iopub.status.idle":"2023-03-05T23:34:51.357281Z","shell.execute_reply.started":"2023-03-05T22:57:01.856608Z","shell.execute_reply":"2023-03-05T23:34:51.356281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8,5))\nplt.legend(fontsize=15)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"CTC Loss Score\")\nplt.title(\"Learning Curve\", fontsize=15)\nplt.grid()\nplt.savefig(\"OCRModel-LearningCurve.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T23:37:09.438779Z","iopub.execute_input":"2023-03-05T23:37:09.439198Z","iopub.status.idle":"2023-03-05T23:37:10.097085Z","shell.execute_reply.started":"2023-03-05T23:37:09.439163Z","shell.execute_reply":"2023-03-05T23:37:10.0882Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model required for inference\ninference_model = keras.Model(\n    inputs=ocr_model.get_layer(name=\"image\").input,\n    outputs=ocr_model.get_layer(name='dense_1').output\n)\n\n# Model summary\ninference_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T23:46:41.714165Z","iopub.execute_input":"2023-03-05T23:46:41.714755Z","iopub.status.idle":"2023-03-05T23:46:41.781289Z","shell.execute_reply.started":"2023-03-05T23:46:41.714719Z","shell.execute_reply":"2023-03-05T23:46:41.78038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_pred(pred_label):\n    \n    '''\n    The decode_pred function is used to decode the predicted labels generated by the OCR model.\n    It takes a matrix of predicted labels as input, where each time step represents the probability \n    for each character. The function uses CTC decoding to decode the numeric labels back into their \n    character values. The function also removes any unknown tokens and returns the decoded texts as a\n    list of strings. The function utilizes the num_to_char function to map numeric values back to their\n    corresponding characters. Overall, the function is an essential step in the OCR process, as it allows\n    us to obtain the final text output from the model's predictions.\n    \n    Argument : \n        pred_label : These are the model predictions which are needed to be decoded.\n        \n    Return:\n        filtered_text : This is the list of all the decoded and processed predictions.\n    \n    '''\n    \n    # Input length\n    input_len = np.ones(shape=pred_label.shape[0]) * pred_label.shape[1]\n    \n    # CTC decode\n    decode = keras.backend.ctc_decode(pred_label, input_length=input_len, greedy=True)[0][0][:,:MAX_LABEL_LENGTH]\n    \n    # Converting numerics back to their character values\n    chars = num_to_char(decode)\n    \n    # Join all the characters\n    texts = [tf.strings.reduce_join(inputs=char).numpy().decode('UTF-8') for char in chars]\n    \n    # Remove the unknown token\n    filtered_texts = [text.replace('[UNK]', \" \").strip() for text in texts]\n    \n    return filtered_texts","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:04:40.417416Z","iopub.execute_input":"2023-03-06T00:04:40.417777Z","iopub.status.idle":"2023-03-06T00:04:40.427953Z","shell.execute_reply.started":"2023-03-06T00:04:40.417744Z","shell.execute_reply":"2023-03-06T00:04:40.426899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(decode_pred(inference_model.predict(test_ds)))","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:04:41.198165Z","iopub.execute_input":"2023-03-06T00:04:41.198629Z","iopub.status.idle":"2023-03-06T00:04:43.234884Z","shell.execute_reply.started":"2023-03-06T00:04:41.198588Z","shell.execute_reply":"2023-03-06T00:04:43.233787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(data=test_ds, model=inference_model, decode_pred=decode_pred, cmap='binary')","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:11:55.91711Z","iopub.execute_input":"2023-03-06T00:11:55.917748Z","iopub.status.idle":"2023-03-06T00:11:57.79669Z","shell.execute_reply.started":"2023-03-06T00:11:55.917709Z","shell.execute_reply":"2023-03-06T00:11:57.794302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(data=valid_ds, model=inference_model, decode_pred=decode_pred, cmap='binary')","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:19:08.725383Z","iopub.execute_input":"2023-03-06T00:19:08.725752Z","iopub.status.idle":"2023-03-06T00:19:10.990327Z","shell.execute_reply.started":"2023-03-06T00:19:08.725719Z","shell.execute_reply":"2023-03-06T00:19:10.98941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input Layer\ninput_images = layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1), name=\"image\")\n\n# Labels : These are added for the training purpose.\ntarget_labels = layers.Input(shape=(None, ), name=\"label\")\n\n# CNN Network\nx = layers.Conv2D(\n    filters=32, \n    kernel_size=3,\n    strides=1,\n    padding='same',\n    activation='relu',\n    kernel_initializer='he_normal'\n)(input_images)\n\nx = layers.Conv2D(\n    filters=32, \n    kernel_size=3,\n    strides=1,\n    padding='same',\n    activation='relu',\n    kernel_initializer='he_normal'\n)(x)\n\nx = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n\nx = layers.Conv2D(\n    filters=64, \n    kernel_size=3,\n    strides=1,\n    padding='same',\n    activation='relu',\n    kernel_initializer='he_normal'\n)(x)\n\nx = layers.Conv2D(\n    filters=128, \n    kernel_size=3,\n    strides=1,\n    padding='same',\n    activation='relu',\n    kernel_initializer='he_normal'\n)(x)\n\nx = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n\n# Encoding Space\nencoding = layers.Reshape(target_shape=((IMG_WIDTH//4), (IMG_HEIGHT//4)*128))(x)\nencoding = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(encoding)\nencoding = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(encoding)\nencoding = layers.Dropout(0.4)(encoding)\n\n# RNN Network\nx = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(encoding)\nx = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n\n# Output Layer\noutput = layers.Dense(len(char_to_num.get_vocabulary())+1, activation='softmax')(x)\n\n# CTC Layer\nctc_layer = CTCLayer()(target_labels, output)\n\n# Model \nocr_model_2 = keras.Model(\n    inputs=[input_images, target_labels],\n    outputs=[ctc_layer]\n)\n\n# Compile\nocr_model_2.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3))\n\n# Train\nhistory_2 = ocr_model_2.fit(\n    train_ds, \n    validation_data=valid_ds, \n    epochs=EPOCHS,\n    callbacks=[\n        callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n    ]\n)\n\n# Learning Curve\npd.DataFrame(history_2.history).plot(figsize=(8,5))\nplt.legend(fontsize=15)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"CTC Loss Score\")\nplt.title(\"Learning Curve\", fontsize=15)\nplt.grid()\n# plt.savefig(\"OCRModel-LearningCurve.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:23:55.838073Z","iopub.execute_input":"2023-03-06T00:23:55.83852Z","iopub.status.idle":"2023-03-06T00:45:44.291253Z","shell.execute_reply.started":"2023-03-06T00:23:55.838481Z","shell.execute_reply":"2023-03-06T00:45:44.290175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model required for inference\ninference_model_2 = keras.Model(\n    inputs=ocr_model_2.get_layer(name=\"image\").input,\n    outputs=ocr_model_2.get_layer(name='dense_4').output\n)\n\n# Model summary\ninference_model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:48:14.816254Z","iopub.execute_input":"2023-03-06T00:48:14.816937Z","iopub.status.idle":"2023-03-06T00:48:14.860645Z","shell.execute_reply.started":"2023-03-06T00:48:14.8169Z","shell.execute_reply":"2023-03-06T00:48:14.859717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(data=test_ds, model=inference_model_2, decode_pred=decode_pred, cmap='binary')","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:48:22.186995Z","iopub.execute_input":"2023-03-06T00:48:22.187704Z","iopub.status.idle":"2023-03-06T00:48:26.793854Z","shell.execute_reply.started":"2023-03-06T00:48:22.187665Z","shell.execute_reply":"2023-03-06T00:48:26.792858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(data=valid_ds, model=inference_model_2, decode_pred=decode_pred, cmap='binary')","metadata":{"execution":{"iopub.status.busy":"2023-03-06T00:49:10.495459Z","iopub.execute_input":"2023-03-06T00:49:10.496025Z","iopub.status.idle":"2023-03-06T00:49:12.64025Z","shell.execute_reply.started":"2023-03-06T00:49:10.495982Z","shell.execute_reply":"2023-03-06T00:49:12.639199Z"},"trusted":true},"execution_count":null,"outputs":[]}]}